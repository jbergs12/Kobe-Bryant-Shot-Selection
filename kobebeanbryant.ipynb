{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.4.0"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5185,"databundleVersionId":37488,"sourceType":"competition"}],"dockerImageVersionId":30749,"isInternetEnabled":true,"language":"r","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Random Forest Model to Predict Kobe's Shot-making Probabilities","metadata":{}},{"cell_type":"markdown","source":"## Introduction","metadata":{}},{"cell_type":"markdown","source":"This notebook was created for the Kobe Bryant Shot Selection competition here on Kaggle. For it, we were given a data set containing information on each of Kobe's shots from his 20-year professional basketball career. The results of 5000 shots were removed (set to NAs), and we will use those shots as the testing data set. All the other shots will be used to train the predictive model.\n\nThe original features of the data are:\naction_type,\r\ncombined_shot_typ),\r\ngame_event_k),\r\ngame_id,\r\nlat,\r\nloc_x,\r\nloc_y,\r\nlon,\r\nminutes_remaining,\r\nperiod,\r\nplayoffs,\r\nseason,\r\nseconds_remaining,\r\nshot_distanit a 2 or a 3),\rs of the court),\restricted area”),nge (“16-st the Lakly just the Lakers),e,\r\nmatchu@UTA),\r\no.\nponent (UTA),\r\nshot_id \r\nResponse Variable: shot_made_flag\r\n","metadata":{}},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":"library(tidyverse)\nlibrary(vroom)\nlibrary(embed)\nlibrary(tidymodels)","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load data\nfull_data <- vroom(\"/kaggle/input/kobe-bryant-shot-selection/data.csv.zip\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Using the Euclidean Distance Formula, I calculated the shot distance by using the x and y coordinates of the shot.","metadata":{}},{"cell_type":"code","source":"# Create distance column\nfull_data$shot_distance <- sqrt((full_data$loc_x/10)^2 + (full_data$loc_y/10)^2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Using trigonometric methods, I calculated the angle at which Kobe took a given shot.","metadata":{}},{"cell_type":"code","source":"# Create angle column\nloc_x_zero <- full_data$loc_x == 0\nfull_data['angle'] <- rep(0,nrow(full_data))\nfull_data$angle[!loc_x_zero] <- atan(full_data$loc_y[!loc_x_zero] / full_data$loc_x[!loc_x_zero])\nfull_data$angle[loc_x_zero] <- pi / 2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"I scaled and aggregated the \"minutes_remaining\" and \"seconds_remaining\" columns into a single \"time_remaining\" column in seconds.","metadata":{}},{"cell_type":"code","source":"# Create single, time variable column\nfull_data$time_remaining <- (full_data$minutes_remaining*60)+full_data$seconds_remaining","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Given that players tend to perform better when they are at home vs. away, I altered the \"matchup\" column to be a binary \"home\" or \"away\" column.","metadata":{}},{"cell_type":"code","source":"# Create home and away column\nfull_data$matchup = ifelse(str_detect(full_data$matchup, 'vs.'), 'Home', 'Away')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"I simplified the \"season\" column by changing the cells from a \"2000-01\" format to a \"1\" (representing Kobe's first season).","metadata":{}},{"cell_type":"code","source":"# Create season column\nfull_data['season'] <- substr(str_split_fixed(full_data$season, '-',2)[,2],2,2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"I created a new column by altering the \"game_date\" column to show the game number.","metadata":{}},{"cell_type":"code","source":"# Create game number column\nfull_data$game_num <- as.numeric(full_data$game_date)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Kobe tore his Achilles tendon during his career which could have affected his shooting ability. I created a column that labels any game after his Achilles with a 1 and any game before with a 0. I don't think the training data contained any 1s, but it's good to have it just in case the testing data does (and it doesn't affect anything if there are only 0s).","metadata":{}},{"cell_type":"code","source":"# Create Achilles injury status column\nfull_data$postachilles <- ifelse(full_data$game_num > 1452, 1, 0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"I also created a column indicating the games during Kobe's MVP season. For whatever reason, I don't think there were any 1s in the training data, but it's also good to have just in case it's in the testing data.","metadata":{}},{"cell_type":"code","source":"# Create MVP status column\nfull_data$mvp <- ifelse(full_data$game_num >= 909 & full_data$game_num <= 990, 1, 0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"I removed unnecessary columns (including a few with zero variance) to reduce noise in the data during prediction and cross-validation. I saved the altered data to a new variable so I can still access the \"shot_id\" column when creating the Kaggle submission at the end without including it in my analysis.","metadata":{}},{"cell_type":"code","source":"# Remove unnecessary columns\nnew_data <- full_data |>\n  select(-c('shot_id', 'team_id', 'team_name', 'shot_zone_range', 'lon', 'lat',\n            'seconds_remaining', 'minutes_remaining', 'game_event_id',\n            'game_id', 'game_date','shot_zone_area',\n            'shot_zone_basic', 'loc_x', 'loc_y'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Create Training and Testing Data Sets","metadata":{}},{"cell_type":"markdown","source":"The training data is based on the rows that indicate whether Kobe made the shot (from the \"shot_made_flag\" column). This filters the training data set to only those rows.","metadata":{}},{"cell_type":"code","source":"# Train\nkobe_train <- new_data |>\n  filter(!is.na(shot_made_flag))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The testing data is based on the rest of the rows where \"shot_made_flag\" is NA.","metadata":{}},{"cell_type":"code","source":"# Test\nkobe_test <- new_data |>\n  filter(is.na(shot_made_flag)) |>\n  select(-shot_made_flag)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Since our response variable is a bunch of \"yes's\" and \"no's\" represented by 1s and 0s, we need to ensure the model reads \"shot_made_flag\" as a categorical variable.","metadata":{}},{"cell_type":"code","source":"# Make the response variable into a factor\nkobe_train$shot_made_flag <- as.factor(kobe_train$shot_made_flag)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We must create a recipe to apply to both the testing and training data sets. First, it turns the \"period\" column into a factor (so it's not interpreted as literal 1s, 2s, 3s, and 4s). \"step_novel\" and \"step_unknown\" account for any discrepancies between the testing and training data sets by assigning a value and a level to categorical data that is present in one but not the other. \"step_dummy\" then dummy encodes all categorical variables.","metadata":{}},{"cell_type":"code","source":"# Create Recipe\nkobe_recipe <- recipe(shot_made_flag~., data = kobe_train) |>\n    step_mutate(period = as.factor(period)) |>\n    step_novel(all_nominal_predictors()) |>\n    step_unknown(all_nominal_predictors()) |>\n    step_dummy(all_nominal_predictors())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Random Forest Model","metadata":{}},{"cell_type":"code","source":"# Run code in parallel\nlibrary(doParallel)\n\nnum_cores <- parallel::detectCores()\n\ncl <- makePSOCKcluster(num_cores)\n\nregisterDoParallel(cl)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This sets up the model. Out of all the models I tried, a classification random forest worked best. I will tune the \"mtry\" and \"min_n\" hyperparameters via cross-validation in the following few code chunks.","metadata":{}},{"cell_type":"code","source":"# Create a workflow with model & recipe\nkobe_forest <- rand_forest(mtry = tune(),\n                         min_n=tune(),\n                         trees=800) |>\n  set_engine(\"ranger\") |>\n  set_mode(\"classification\")\n\n\nkobe_wf <- workflow() |>\n  add_recipe(kobe_recipe) |>\n  add_model(kobe_forest)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This sets up different values to try for the hyperparameters during cross-validation.","metadata":{}},{"cell_type":"code","source":"# Set up grid of tuning values\nforest_grid <- grid_regular(mtry(range = c(1,(ncol(kobe_train)-1))),\n                            min_n(),\n                            levels = 3)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This sets up a 3-fold cross-validation.","metadata":{}},{"cell_type":"code","source":"# Set up K-fold CV\nfolds <- vfold_cv(kobe_train, v = 3, repeats=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This runs the cross-validation and evaluates the mean log loss for each fold. I then extracted the model that had the best mean log loss.","metadata":{}},{"cell_type":"code","source":"# Find the best tuning parameters\nCV_results <- kobe_wf |>\n  tune_grid(resamples=folds,\n            grid=forest_grid,\n            metrics=metric_set(mn_log_loss))\n\nbestTune <- CV_results |>\n  select_best(metric=\"mn_log_loss\")\n\nbestTune$min_n\nbestTune$mtry","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Predictions","metadata":{}},{"cell_type":"markdown","source":"This finalizes the workflow with the newly-tuned model, and it predicts on the test set.","metadata":{}},{"cell_type":"code","source":"# Finalize workflow and predict\nfinal_wf <- kobe_wf |>\n  finalize_workflow(bestTune) |>\n  fit(data=kobe_train)\n\npreds <- final_wf |>\n  predict(new_data=kobe_test,\n          type=\"prob\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We then format the predictions to meet the Kaggle competition requirements and write the submission file to be submitted.","metadata":{}},{"cell_type":"code","source":"# Write Kaggle Submission\nkaggle_submission <- full_data |> \n  filter(is.na(shot_made_flag)) |>\n  bind_cols(preds) |> \n  select(shot_id, .pred_1) |> \n  rename(shot_made_flag = .pred_1)\n\nvroom_write(x=kaggle_submission, file=\"kobe_forest.csv\", delim = \",\")\n\nstopCluster(cl)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}